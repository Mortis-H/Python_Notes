import streamlit as st
import requests

# è¨­å®š LM Studio API çš„åŸºæœ¬ URL
LM_STUDIO_API_URL = "http://localhost:1234/v1/chat/completions"

# åˆå§‹åŒ–èŠå¤©æ­·å²
if "chat_history" not in st.session_state:
    st.session_state.chat_history = []

# ä¸»è¦ä»‹é¢
st.title("æœ¬åœ° LLM èŠå¤©å®¤")

# é¡¯ç¤ºèŠå¤©è¨˜éŒ„
for message in st.session_state.chat_history:
    role = "ğŸ§‘ ä½¿ç”¨è€…" if message["role"] == "user" else "ğŸ¤– åŠ©æ‰‹"
    st.write(f"{role}ï¼š{message['content']}")

# ä½¿ç”¨è€…è¼¸å…¥
user_input = st.text_area("è«‹è¼¸å…¥è¨Šæ¯", height=100, key="user_input")

# é€å‡ºæŒ‰éˆ•
if st.button("é€å‡º") and user_input.strip():
    # å°‡ç”¨æˆ¶è¼¸å…¥åŠ å…¥èŠå¤©è¨˜éŒ„
    st.session_state.chat_history.append({"role": "user", "content": user_input})

    # æº–å‚™å°è©±æ­·å²
    messages = [
        {"role": "system", "content": "ä½ æ˜¯ä¸€å€‹æœ‰å¹«åŠ©çš„AIåŠ©æ‰‹ã€‚è«‹ç”¨ä¸­æ–‡å›ç­”ã€‚"},
    ] + [
        {"role": msg["role"], "content": msg["content"]}
        for msg in st.session_state.chat_history
    ]

    # ç™¼é€è«‹æ±‚åˆ° LM Studio
    try:
        payload = {
            "messages": messages,
            "temperature": 0.7,
            "max_tokens": 500,
            "stream": False
        }
        
        response = requests.post(
            LM_STUDIO_API_URL, 
            json=payload,
            headers={"Content-Type": "application/json"}
        )
        response.raise_for_status()
        
        model_reply = response.json()["choices"][0]["message"]["content"].strip()
        st.session_state.chat_history.append({"role": "assistant", "content": model_reply})
        
    except Exception as e:
        st.error(f"èˆ‡æ¨¡å‹é€šè¨Šæ™‚ç™¼ç”ŸéŒ¯èª¤: {str(e)}")

# æ¸…ç©ºèŠå¤©è¨˜éŒ„æŒ‰éˆ•
if st.button("æ¸…ç©ºèŠå¤©è¨˜éŒ„"):
    st.session_state.chat_history = []
    st.experimental_rerun()
